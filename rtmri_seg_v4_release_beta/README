This package contains a Matlab software for an automatic parameterization of midsagittal vocal tract images, recorded using real-time Magnetic Resonance Imaging (rtMRI).
If you have any question, please email to jangwon@usc.edu.
Aug 6 2015

Updates in Version 4
- The way of grid-line construction has been changed.
  The center of grid lines is now "manually" drawn so that users can construct grid lines easily for various head postures and morphological shapes.
  Also, the number of landmark points that manual selected is now three (no alveolar ridge).
- Matlab codes have been cleaned.
    options.m contains all parameter values that users may want to change depending on their data.
    path.m contains the paths of input and output data.
- The index of the grid lines starts from the lip region and ends at the larynx region. (opposite way from previous versions).
- Ignore MR images for silence regions if silence labels. The format of the silence label file is:
    column 1: starting time (in second)
    column 2: ending time (in second)

  Filename should have the same basename with the mat data file, but with the extension of "lab_sil"
    e.g.) utt_001.lab_sil for utt_001.mat
- If estimated inner and outer tissue-airway boundaries cross each other, fix them (use their mean values).

The details of parameter extraction algorithm is provided in [1].
If you use any part of this software, cite [1].



*Note: I appologize that the current version of this software does not have detailed comments in it.
Instead, this software provides f_plot_*.m files that shows how to assess each estimated vocal tract parameter for plot.

Main outputs:
1. Tissue-airway boundaries: bnd_out.bin_lb_c (inner boundary bins) and bnd_out.bin_rt_c (outer boundary bins)
   bnd_out offers the bin indeces for the boundaries. XY-coordinates can be easily computed using f_bin2pts.m as follows:
   pts_lb_c = f_bin2pts(bnd_out.bin_lb_c,grid,track_out.idx_lips,track_out.idx_larynx);
   pts_rt_c = f_bin2pts(bnd_out.bin_rt_c,grid,track_out.idx_lips,track_out.idx_larynx);
2. Anatomical landmark (front-most point of the lips and the top of the larynx) tracking: track_out
3. Distance function (from the shortest opening point in the lip region to the top of the larynx): vt_dL
4. Center point of airway in the oropharyngeal vocal tract: pts_c
5. Vocal tract length (Geodesic distance from the lips to the larynx): vtl 



JPG images in ./fig:
- Fig_Centers_and_Landmarks.jpg: An example MR image (reference image) and standard deviation image with center points of grid lines and/or 3 landmark points on them. You will be asked to draw the center line and choose the 3 landmark points manually as the example figure shows.
- Fig_Constructed_Grid_Lines.jpg: An example MR image with smoothed and interpolated centers of grid lines and corresponding grid lines
- Fig_Region_of_Airway_Path_Estimation.jpg: Oral pharyngeal airway path will be determined wihin the cyan lines. You may want to reduce/increase the length of the lines if estimated airway path is too much erroneous.



Four main procedures and the corresponding (wrapper) codes:
- Prepare your data: ./script/conv_avi_to_mat.m
  Create MAT files from AVI files, which will be the inputs for wrapper_grid.m and wrapper_seg_batch.m.
- Set parameters and paths: ./config/options.m for parameters and ./paths.m for paths.
- Construct grid lines: ./code_wrapper/wrapper_grid.m
  The grid line constructed will be used for parameter extraction in batch by wrapper_seg_batch.m.
- Extract Vocal tract parameters automatically in batch: ./code_wrapper/wrapper_seg_batch.m
  This code load the grid line file (grid.mat) that is generated by wrapper_grid.m.
- Extract morphological parameters automatically in batch: ./code_wrapper/wrapper_morph.m
  This code loads the vocal tract parameters generated using wrapper_grid.m, and compute the vocal tract length and the center points of airway in the oropharyngeal airway.



Some other functions in ./script:
flip_ud_video_mat.m - flip MR video upside down. Make sure that the subject is upright and is facing left in your image data.
head_cor_manual.m - The code for manual head alignment. This code allows user to interactively find the optimal parameters (translations in the horizontal and vertical directions, as well as rotation) based on overlaid edge image of a certain reference image. This code applies a set of the parameters obtained from one image of a file to the entire image frames of the file.



Demo data:
rtMRIdata - The directory of demo video files in mat format. These files are a subset of the USC-EMO-MRI corpus [2].



Tips for better segmentation results on your dataset:
You may want to change the parameter values in options.m for obtaining nice vocal tract parameters.
Jangwon Kim (jangwon@usc.edu) will be happy to discuss how to choose the parameters for your data.
Here is a rough guide for some cases.

1. When larynx tracking shows error: 
=> It has been observed that the epiglottis can cause larynx tracking error. You may be able to reduce this error (1) by changing the scope of the larynx tracking to be smaller and (2) by placing the first landmark (larynx) near the pharyngeal wall instead of the center of the airway path near the top of the larynx in the reference image. Relevant parameters for (1) are opt.lar.search_width_larynx_mm (# grid lines in search) and opt.lar.search_length_larynx_mm (the length of each line).

2. When estimated airway path has too much error: 
=> The key of robust airway path estimation is quantile smoothing with neighbors in the 3D observation cost matrix. If the airway path has significant error even after unsupervised smoothing (by f_sm_airway_path), you may be able to reduce this error (1) by changing parameters (opt.airway.obslik_sm_frame_span, opt.airway.obslik_sm_grid_span, opt.airway.obslik_sm_bin_span) for the quantile smoothing and (2) by changing sigmoid function parameter (opt.airway.sigmoid_param_air). For (1), we do not provide specific guides how to change these parameters, but for the USC-TIMIT corpus [3] and the USC-EMO-MRI corpus [2], opt.airway.obslik_sm_{frame,grid,bin} = 2-5 were good. For (2), higher value of the 1st element and lower value of the 2nd element of "sigmoid_param_air" often helps to reduce the error.

If you are still not able to fix your error, please email to jangwon@usc.edu for help.



References:
[1] Jangwon Kim, Naveen Kumar, Sungbok Lee and Shrikanth Narayanan, "Enhanced airway-tissue boundary segmentation for real-time magnetic resonance imaging data," in 10-th International Seminar on Speech Production (ISSP), Cologne, Germany, 2014, pages 222-225
[2] Jangwon Kim, Asterios Toutios, Yoon-Chul Kim, Yinghua Zhu, Sungbok Lee and Shrikanth Narayanan, "USC-EMO-MRI corpus: An emotional speech production database recorded by real-time magnetic resonance imaging", in Proceedings of 10-th International Seminar on Speech Production (ISSP), Cologne, Germany, 2014, pages 102-105
[3] Shrikanth Narayanan, Asterios Toutios, Vikram Ramanarayanan, Adam Lammert, Jangwon Kim, Sungbok Lee, Krishna Nayak, Yoon-Chul Kim, Yinghua Zhu, Louis Goldstein, Dani Byrd, Erik Bresch, Prasanta Ghosh, Athanasios Katsamanis, and Michael Proctor, "Real-time magnetic resonance imaging and electromagnetic articulography database for speech production research," The Journal of the Acoustical Society of America (TC), 136(3), pages 1307 - 1311, 2014



END
